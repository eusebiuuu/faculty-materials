{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SQI96ZI8MdF7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_y(x, W, bias):\n",
    "  # dreapta de decizie: [x, y] * [W[0], W[1]] + b = 0\n",
    "  # => x * W[0] + y * W[1] + b = 0\n",
    "  # => y = (-x * W[0] - b) / W[1]\n",
    "  return (-x * W[0] - bias) / (W[1] + 1e-10) # Adaugam 1e-10 ca să evitam impartirea la zero daca W[1] este exact 0.\n",
    "\n",
    "def plot_decision_boundary(X, y , W, b, current_x, current_y):\n",
    "\n",
    "  # Alegem doua puncte ca sa putem desena o linie intre ele\n",
    "  x1 = -0.5\n",
    "  y1 = compute_y(x1, W, b)\n",
    "  x2 = 0.5\n",
    "  y2 = compute_y(x2, W, b)\n",
    "\n",
    "  # Stergem continutul ferestrei actuale (clf = clear figure)\n",
    "  plt.clf()\n",
    "\n",
    "  # Alegem culoarea (pentru clasa -1 o sa avem albastru, altfel rosu)\n",
    "  color = 'r'\n",
    "  if(current_y == -1):\n",
    "    color = 'b'\n",
    "\n",
    "  # Setam limitele plotului (mini-zoom)\n",
    "  plt.ylim((-1, 2))\n",
    "  plt.xlim((-1, 2))\n",
    "\n",
    "  # Plotam toate punctele de train, separate pe clase:\n",
    "  plt.plot(X[y == -1, 0], X[y == -1, 1], 'b+')\n",
    "  plt.plot(X[y == 1, 0], X[y == 1, 1], 'r+')\n",
    "\n",
    "  # Plotam exemplul curent - cel pe care modelul il procesează acum\n",
    "  plt.plot(current_x[0], current_x[1], color+'s')\n",
    "\n",
    "  # Desenam dreapta de decizie a modelului\n",
    "  plt.plot([x1, x2] ,[y1, y2], 'black')\n",
    "  plt.show(block=False)\n",
    "  plt.pause(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5_TaDDZo4kfd",
    "outputId": "141d4960-5572-4342-846f-ec05774e5abf"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JOk-f2WN4qB8",
    "outputId": "daab19b5-2cb0-4504-9125-806d4c3ac219"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8B8YlIgtwlL9"
   },
   "source": [
    "#### Exercitiul 2\n",
    "\n",
    "Implementarea algoritmului widrow-hoff:\n",
    "  - Initializam weight-urile cu 0\n",
    "  - Amestecam datele de antrenare\n",
    "  - Pentru fiecare exemplu din setul de antrenare updatam weight-urile perceptronului cu ajutorul gradientilor.\n",
    "  - Repetam ultimii 2 pasi pentru un anumit numar de epoci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3 -8 -6 -9]\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = [2, 3, 3, 4]\n",
    "\n",
    "W = [[5, 4, 6, 7]]\n",
    "\n",
    "print(np.subtract(W[0], np.multiply(4, X)))\n",
    "\n",
    "print(round(-0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "mja31jERNDne"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def widrow_hoff(X, Y, num_epochs, learning_rate):\n",
    "  '''\n",
    "  Params:\n",
    "  X = Train inputs\n",
    "  Y = Train Labels\n",
    "  num_epochs = number of epochs the neural network will train for\n",
    "\n",
    "  This method initializes and trains a neural network with two weights using the widrow-hoff method.\n",
    "  '''\n",
    "  X = np.array(X)\n",
    "  Y = np.array(Y)\n",
    "  \n",
    "  features_count = len(X[0])\n",
    "  input_count = len(X)\n",
    "\n",
    "  W = np.ones((1, features_count))\n",
    "  bias = 0\n",
    "\n",
    "  for i in range(1, num_epochs + 1):\n",
    "    X, Y = shuffle(X, Y, random_state=0)\n",
    "    accuracy = []\n",
    "\n",
    "    for t in range(0, input_count):\n",
    "      temp_Y = np.add(X[t] @ W.T, bias)\n",
    "      curr_y = temp_Y[0]\n",
    "      loss = ((curr_y - Y[t]) ** 2) / 2\n",
    "      accuracy.append(np.sign(curr_y) == Y[t])\n",
    "      print(curr_y, Y[t])\n",
    "\n",
    "      W[0] = np.subtract(W[0], np.multiply(learning_rate * (curr_y - Y[t]), X[t]))\n",
    "      bias -= learning_rate * (curr_y - Y[t])\n",
    "      \n",
    "      # plot_decision_boundary(X, Y, W[0], bias, X[t], curr_y)\n",
    "    \n",
    "    print(f\"Accuracy: {np.mean(accuracy)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "ApG-WYOunRrE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1\n",
      "2.0 1\n",
      "0.8 1\n",
      "-0.08000000000000002 -1\n",
      "Accuracy: 1.0\n",
      "0.748 1\n",
      "-0.1468 -1\n",
      "1.61308 1\n",
      "0.545264 1\n",
      "Accuracy: 1.0\n",
      "1.5201032 1\n",
      "0.5321905599999999 1\n",
      "-0.25318377599999997 -1\n",
      "0.5040162816 1\n",
      "Accuracy: 1.0\n",
      "-0.27826702655999996 -1\n",
      "0.531039727936 1\n",
      "0.5753919273024 1\n",
      "1.5886896208883199 1\n",
      "Accuracy: 1.0\n",
      "0.542575617664256 1\n",
      "1.5035676110889729 1\n",
      "0.4945835814566758 1\n",
      "-0.2740251325376625 -1\n",
      "Accuracy: 1.0\n",
      "0.5230693784191068 1\n",
      "-0.29892955712580693 -1\n",
      "1.4062622047534712 1\n",
      "0.4076247039416845 1\n",
      "Accuracy: 1.0\n",
      "1.4028586025390928 1\n",
      "0.44552804264552903 1\n",
      "-0.335263956801204 -1\n",
      "0.43473541801075244 1\n",
      "Accuracy: 1.0\n",
      "-0.34521110292215884 -1\n",
      "0.4823094447008178 1\n",
      "0.5327654538176025 1\n",
      "1.5709808559147609 1\n",
      "Accuracy: 1.0\n",
      "0.5120161918711298 1\n",
      "1.4972833607661067 1\n",
      "0.46771654785560746 1\n",
      "-0.3169971781225455 -1\n",
      "Accuracy: 1.0\n",
      "0.5058729560967405 1\n",
      "-0.33588475591996503 -1\n",
      "1.4186686451500563 1\n",
      "0.39435179532268744 1\n",
      "Accuracy: 1.0\n",
      "1.4141976925405018 1\n",
      "0.4326418977500496 1\n",
      "-0.368282283404298 -1\n",
      "0.4258424319644334 1\n",
      "Accuracy: 1.0\n",
      "-0.3740382982603116 -1\n",
      "0.4780777753975779 1\n",
      "0.5299535556302996 1\n",
      "1.5908673107963403 1\n",
      "Accuracy: 1.0\n",
      "0.5057893823449716 1\n",
      "1.512449241088444 1\n",
      "0.45822461614357846 1\n",
      "-0.34417065657440155 -1\n",
      "Accuracy: 1.0\n",
      "0.500996758572303 1\n",
      "-0.3598532667741917 -1\n",
      "1.4372725861535938 1\n",
      "0.38916739529084093 1\n",
      "Accuracy: 1.0\n",
      "1.4282573312493474 1\n",
      "0.42568244998280325 1\n",
      "-0.39190591636443106 -1\n",
      "0.4213823571637519 1\n",
      "Accuracy: 1.0\n",
      "-0.39485356044436315 -1\n",
      "0.47659124177543777 1\n",
      "0.5294245477732031 1\n",
      "1.6078399602163833 1\n",
      "Accuracy: 1.0\n",
      "0.5019716461752858 1\n",
      "1.5250936429164113 1\n",
      "0.4515466533989424 1\n",
      "-0.3646149736254932 -1\n",
      "Accuracy: 1.0\n",
      "0.49769882008170324 1\n",
      "-0.37792335827111423 -1\n",
      "1.4519702885350196 1\n",
      "0.3854938164915387 1\n",
      "Accuracy: 1.0\n",
      "1.4392804386762057 1\n",
      "0.42053896545798974 1\n",
      "-0.40985937336007816 -1\n",
      "0.4180839055912839 1\n",
      "Accuracy: 1.0\n",
      "-0.41068182658319874 -1\n",
      "0.475535307131347 1\n",
      "0.5291233710884564 1\n",
      "1.6208941172138562 1\n",
      "Accuracy: 1.0\n",
      "0.4991198734279939 1\n",
      "1.5348019073641006 1\n",
      "0.4464647163378411 1\n",
      "-0.38020757318123843 -1\n",
      "Accuracy: 1.0\n",
      "0.4951925303883967 1\n",
      "-0.39170606890195425 -1\n",
      "1.4632212500179422 1\n",
      "0.3827169068016821 1\n",
      "Accuracy: 1.0\n",
      "1.447711493652223 1\n",
      "0.416631226710901 1\n",
      "-0.42356354973003363 -1\n",
      "0.41555962408862485 1\n",
      "Accuracy: 1.0\n",
      "-0.42276315716589274 -1\n",
      "0.4747240149874891 1\n",
      "0.528909288150702 1\n",
      "1.6308658854586051 1\n",
      "Accuracy: 1.0\n",
      "0.4969542534288406 1\n",
      "1.5422152691352558 1\n",
      "0.44257662691326494 1\n",
      "-0.39211137525671924 -1\n",
      "Accuracy: 1.0\n",
      "0.4932724390562839 1\n",
      "-0.4022274816366757 -1\n",
      "1.4718147608901087 1\n",
      "0.38060637583038415 1\n",
      "Accuracy: 1.0\n",
      "1.4541490574569993 1\n",
      "0.41365528917290745 1\n",
      "-0.4340272818080481 -1\n",
      "0.4136244974197486 1\n",
      "Accuracy: 1.0\n",
      "-0.4319870033692182 -1\n",
      "0.47409829827272065 1\n",
      "0.5287533802868056 1\n",
      "1.6384794757071894 1\n",
      "Accuracy: 1.0\n",
      "0.4953068090880065 1\n",
      "1.547874271177431 1\n",
      "0.43960187030377107 1\n",
      "-0.4011997135158888 -1\n",
      "Accuracy: 1.0\n",
      "0.49180146759460575 1\n",
      "-0.4102598889237605 -1\n",
      "1.4783772824884913 1\n",
      "0.379000762991348 1\n",
      "Accuracy: 1.0\n",
      "1.4590639451436744 1\n",
      "0.4113878213643436 1\n",
      "-0.4420168812301702 -1\n",
      "0.4121417471290755 1\n",
      "Accuracy: 1.0\n",
      "-0.4390293678200607 -1\n",
      "0.4736163344852664 1\n",
      "0.5286390738350638 1\n",
      "1.6442923911428458 1\n",
      "Accuracy: 1.0\n",
      "0.494052780839482 1\n",
      "1.5521941176320955 1\n",
      "0.4373265803657705 1\n",
      "-0.40813855886810696 -1\n",
      "Accuracy: 1.0\n",
      "0.49067512017942716 1\n",
      "-0.41639221499923895 -1\n",
      "1.4833886196201618 1\n",
      "0.377778584553349 1\n",
      "Accuracy: 1.0\n",
      "1.4628163168234436 1\n",
      "0.40965960427799053 1\n",
      "-0.4481173060268095 -1\n",
      "0.4110062420742915 1\n",
      "Accuracy: 1.0\n",
      "-0.4444061996315577 -1\n",
      "0.473245613622589 1\n",
      "0.5285548484185412 1\n",
      "1.6487305106635652 1\n",
      "Accuracy: 1.0\n",
      "0.4930977766021198 1\n",
      "1.5554918021440711 1\n",
      "0.4355867658344778 1\n",
      "-0.41343631139693837 -1\n",
      "Accuracy: 1.0\n",
      "0.489813043807276 1\n",
      "-0.42107398463797213 -1\n",
      "1.4872153291759902 1\n",
      "0.3768478436569991 1\n",
      "Accuracy: 1.0\n",
      "1.465681161691793 1\n",
      "0.4083420425872406 1\n",
      "-0.4527752238853772 -1\n",
      "0.4101370691001751 1\n",
      "Accuracy: 1.0\n",
      "-0.448511408406857 -1\n",
      "0.47296079612082575 1\n",
      "0.5284925107769158 1\n",
      "1.6521189926964475 1\n",
      "Accuracy: 1.0\n",
      "0.4923702100822431 1\n",
      "1.5580092528710643 1\n",
      "0.43425671569724233 1\n",
      "-0.41748111539064525 -1\n",
      "Accuracy: 1.0\n",
      "0.4891534840968584 1\n",
      "-0.42464835226126657 -1\n",
      "1.490137383816116 1\n",
      "0.37613876751413944 1\n",
      "Accuracy: 1.0\n",
      "1.4678684151684536 1\n",
      "0.4073373309776209 1\n",
      "-0.4563317067827729 -1\n",
      "0.4094720235358009 1\n",
      "Accuracy: 1.0\n",
      "-0.45164573845807565 -1\n",
      "0.4727421926744483 1\n",
      "0.5284461876851567 1\n",
      "1.6547060881673967 1\n",
      "Accuracy: 1.0\n",
      "0.491815732514646 1\n",
      "1.5599311152142485 1\n",
      "0.4332401214432493 1\n",
      "-0.42056930838218265 -1\n",
      "Accuracy: 1.0\n",
      "0.48864902799281773 1\n",
      "-0.4273772803432461 -1\n",
      "1.4923686096353037 1\n",
      "0.3755983849707424 1\n",
      "Accuracy: 1.0\n",
      "1.4695383497505636 1\n",
      "0.4065710380264812 1\n",
      "-0.45904719054723064 -1\n",
      "0.40896333530640605 1\n",
      "Accuracy: 1.0\n",
      "-0.4540388050231482 -1\n",
      "0.47257454874743965 1\n",
      "0.5284116415728384 1\n",
      "1.6566813316517996 1\n",
      "Accuracy: 1.0\n",
      "0.49139304692791064 1\n",
      "1.5613983227706778 1\n",
      "0.4324632392633815 1\n",
      "-0.42292713761423806 -1\n",
      "Accuracy: 1.0\n",
      "0.48826330517212907 1\n",
      "-0.4294607543700271 -1\n",
      "1.4940723062507988 1\n",
      "0.3751864464929088 1\n",
      "Accuracy: 1.0\n",
      "1.4708133250769775 1\n",
      "0.40598649217893146 1\n",
      "-0.4611205359329861 -1\n",
      "0.40857435303526524 1\n",
      "Accuracy: 1.0\n",
      "-0.45586591764321394 -1\n",
      "0.4724460741925336 1\n",
      "0.5283857963779852 1\n",
      "1.658189429754561 1\n",
      "Accuracy: 1.0\n",
      "0.4910707511514761 1\n",
      "1.5625184505978975 1\n",
      "0.431869628530589 1\n",
      "-0.42472733893939674 -1\n",
      "Accuracy: 1.0\n",
      "0.4879684367184109 1\n",
      "-0.43105144871729817 -1\n",
      "1.495373181134398 1\n",
      "0.3748723468154914 1\n",
      "Accuracy: 1.0\n",
      "1.4717867574309802 1\n",
      "0.40554052596619716 1\n",
      "-0.462703584980275 -1\n",
      "0.4082769777532418 1\n",
      "Accuracy: 1.0\n",
      "-0.4572609242575716 -1\n",
      "0.4723476746283506 1\n",
      "0.5283664064585831 1\n",
      "1.659340864164197 1\n",
      "Accuracy: 1.0\n",
      "0.4908249523340271 1\n",
      "1.563373614448132 1\n",
      "0.4314161081009537 1\n",
      "-0.42610179384523883 -1\n",
      "Accuracy: 1.0\n",
      "0.4877430658652868 1\n",
      "-0.43226592104724365 -1\n",
      "1.4963664668096925 1\n",
      "0.374632799708281 1\n",
      "Accuracy: 1.0\n",
      "1.4725299668251286 1\n",
      "0.40520024640159913 1\n",
      "-0.46391227691698944 -1\n",
      "0.4080496811507005 1\n",
      "Accuracy: 1.0\n",
      "-0.45832601734036055 -1\n",
      "0.4722723466545964 1\n",
      "0.5283518237664845 1\n",
      "1.6602199866086491 1\n",
      "Accuracy: 1.0\n",
      "0.4906374616914577 1\n",
      "1.5640264982877627 1\n",
      "0.4310696517986006 1\n",
      "-0.42715119248707967 -1\n",
      "Accuracy: 1.0\n",
      "0.4875708406875885 1\n",
      "-0.43319315730713054 -1\n",
      "1.4971248852836172 1\n",
      "0.37445007836969235 1\n",
      "Accuracy: 1.0\n",
      "1.4730974040245934 1\n",
      "0.40494058189083515 1\n",
      "-0.4648351365332912 -1\n",
      "0.40787597804641806 1\n",
      "Accuracy: 1.0\n",
      "-0.4591392206846039 -1\n",
      "0.4722147045055948 1\n",
      "0.5283408329792564 1\n",
      "1.6608911990545843 1\n",
      "Accuracy: 1.0\n",
      "0.4904944265724883 1\n",
      "1.5645249540237112 1\n",
      "0.43080500703364233 1\n",
      "-0.42795241103307124 -1\n",
      "Accuracy: 1.0\n",
      "0.487439246730221 1\n",
      "-0.4339010946027862 -1\n",
      "1.4977039676274109 1\n",
      "0.37431068211496576 1\n",
      "Accuracy: 1.0\n",
      "1.4735306409161946 1\n",
      "0.40474241750873374 1\n",
      "-0.465539755959238 -1\n",
      "0.4077432507692882 1\n",
      "Accuracy: 1.0\n",
      "-0.45976010544024304 -1\n",
      "0.4721706111594549 1\n",
      "0.5283325339540609 1\n",
      "1.661403672102977 1\n",
      "Accuracy: 1.0\n",
      "0.49038529274265336 1\n",
      "1.5649055119235533 1\n",
      "0.4306028694525864 1\n",
      "-0.42856414402974724 -1\n",
      "Accuracy: 1.0\n",
      "0.4873387099650438 1\n",
      "-0.4344416006232769 -1\n",
      "1.4981461169282637 1\n",
      "0.3742043249472987 1\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "y = np.array([-1, 1, 1, 1])\n",
    "widrow_hoff(x, y, 70, 0.1)\n",
    "\n",
    "# Does it work ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzd5rGnsxzHZ"
   },
   "source": [
    "#### Exercitiul 3\n",
    "\n",
    "Pentru exercitiul 3 putem vedea ca perceptronul nu mai este capabil sa invete o functie de decizie suficient de complexa pentru a discrimina setul de antrenare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "_V5DQte3nZIi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1\n",
      "2.0 -1\n",
      "0.3999999999999999 1\n",
      "-0.24000000000000005 -1\n",
      "Accuracy: 0.75\n",
      "0.44399999999999995 1\n",
      "-0.2604000000000001 -1\n",
      "1.1812399999999998 -1\n",
      "-0.07060800000000012 1\n",
      "Accuracy: 0.5\n",
      "0.7409895999999998 -1\n",
      "-0.20468432000000014 1\n",
      "-0.49905372800000003 -1\n",
      "-0.12577131520000007 1\n",
      "Accuracy: 0.25\n",
      "-0.43657122368 -1\n",
      "0.04304007020799999 1\n",
      "0.1380881636671999 1\n",
      "0.9421206954329601 -1\n",
      "Accuracy: 0.75\n",
      "-0.07795360815283214 1\n",
      "0.5750752084336382 -1\n",
      "-0.2750205801583565 1\n",
      "-0.427449096255061 -1\n",
      "Accuracy: 0.25\n",
      "-0.07727155450117901 1\n",
      "-0.376977031179437 -1\n",
      "0.45345368557890375 -1\n",
      "-0.3523968391153708 1\n",
      "Accuracy: 0.25\n",
      "0.28789694772830676 -1\n",
      "-0.3394968608379581 1\n",
      "-0.4442250213968815 -1\n",
      "-0.25877779500942066 1\n",
      "Accuracy: 0.25\n",
      "-0.3739247397562513 -1\n",
      "-0.06962976203191135 1\n",
      "0.04305824314908002 1\n",
      "0.7083120744711698 -1\n",
      "Accuracy: 0.5\n",
      "-0.10721582037497002 1\n",
      "0.4172616162048129 -1\n",
      "-0.2744027900381367 1\n",
      "-0.30827062191863064 -1\n",
      "Accuracy: 0.25\n",
      "-0.08869516983864623 1\n",
      "-0.268574042742903 -1\n",
      "0.322387189784879 -1\n",
      "-0.3397081550440828 1\n",
      "Accuracy: 0.25\n",
      "0.19361266385823184 -1\n",
      "-0.3104890568069126 1\n",
      "-0.3282969026478243 -1\n",
      "-0.24944929087536705 1\n",
      "Accuracy: 0.25\n",
      "-0.27052228329550515 -1\n",
      "-0.07250720437074304 1\n",
      "0.04368632267341391 1\n",
      "0.6131626291710172 -1\n",
      "Accuracy: 0.5\n",
      "-0.0876834676954723 1\n",
      "0.34675053395880634 -1\n",
      "-0.2455886816203533 1\n",
      "-0.20325206817762154 -1\n",
      "Accuracy: 0.25\n",
      "-0.07614573847852052 1\n",
      "-0.17531228751200734 -1\n",
      "0.24492869335990208 -1\n",
      "-0.3184527420412694 1\n",
      "Accuracy: 0.25\n",
      "0.1351406337601852 -1\n",
      "-0.2817903203850526 1\n",
      "-0.23576368523018315 -1\n",
      "-0.23579855268998268 1\n",
      "Accuracy: 0.25\n",
      "-0.18860746143816653 -1\n",
      "-0.06977809600816948 1\n",
      "0.04756252322860818 1\n",
      "0.5449964474698838 -1\n",
      "Accuracy: 0.5\n",
      "-0.07094927091109027 1\n",
      "0.29568736741113677 -1\n",
      "-0.22162056501449146 1\n",
      "-0.12233655591193766 -1\n",
      "Accuracy: 0.25\n",
      "-0.06506279642039942 1\n",
      "-0.10359662067870397 -1\n",
      "0.18691114713383816 -1\n",
      "-0.30201746583531397 1\n",
      "Accuracy: 0.25\n",
      "0.09124129616074947 -1\n",
      "-0.25986223190040103 1\n",
      "-0.1648642331667208 -1\n",
      "-0.22464667063712307 1\n",
      "Accuracy: 0.25\n",
      "-0.12591314278633642 -1\n",
      "-0.06712602223106479 1\n",
      "0.05036522136180373 1\n",
      "0.4932005855891874 -1\n",
      "Accuracy: 0.5\n",
      "-0.058347940028394496 1\n",
      "0.2569099979181101 -1\n",
      "-0.2029246626196523 1\n",
      "-0.060529546506701726 -1\n",
      "Accuracy: 0.25\n",
      "-0.05628677544505167 1\n",
      "-0.048847914311526394 -1\n",
      "0.14261703223744066 -1\n",
      "-0.28972486816553256 1\n",
      "Accuracy: 0.25\n",
      "0.05777689619931489 -1\n",
      "-0.24333527377228908 1\n",
      "-0.11069650153026717 -1\n",
      "-0.21584775026543096 1\n",
      "Accuracy: 0.25\n",
      "-0.07804207635069735 -1\n",
      "-0.06487399257727501 1\n",
      "0.0522778130545358 1\n",
      "0.45367352583970877 -1\n",
      "Accuracy: 0.5\n",
      "-0.04891245472431316 1\n",
      "0.2273539590326587 -1\n",
      "-0.18844122686931583 1\n",
      "-0.013345631091227578 -1\n",
      "Accuracy: 0.25\n",
      "-0.049418418386329904 1\n",
      "-0.0070692261434718295 -1\n",
      "0.10876118609746016 -1\n",
      "-0.2805255425564398 1\n",
      "Accuracy: 0.25\n",
      "0.032237938779510006 -1\n",
      "-0.2308680218010539 1\n",
      "-0.06932285958107232 -1\n",
      "-0.2089559946762542 1\n",
      "Accuracy: 0.25\n",
      "-0.041494974155339676 -1\n",
      "-0.06301529832546937 1\n",
      "0.05358449523297043 1\n",
      "0.4234993044332596 -1\n",
      "Accuracy: 0.5\n",
      "-0.04183226470027561 1\n",
      "0.2048159660433368 -1\n",
      "-0.17725051580896434 1\n",
      "0.022674354572708513 -1\n",
      "Accuracy: 0.0\n",
      "-0.04406784810444231 1\n",
      "0.02481370392588189 -1\n",
      "0.08288604316315804 -1\n",
      "-0.27362318306003786 1\n",
      "Accuracy: 0.0\n",
      "0.012744866826218226 -1\n",
      "-0.22144751981327393 1\n",
      "-0.03772368717831276 -1\n",
      "-0.20358239186885482 1\n",
      "Accuracy: 0.25\n",
      "-0.013593079273595987 -1\n",
      "-0.06150660556772426 1\n",
      "0.05448256053822967 1\n",
      "0.4004638747658683 -1\n",
      "Accuracy: 0.5\n",
      "-0.03650672652258993 1\n",
      "0.18762605764062584 -1\n",
      "-0.16862085433704221 1\n",
      "0.05017239800202687 -1\n",
      "Accuracy: 0.0\n",
      "-0.03991392326983645 1\n",
      "0.04914655052880784 -1\n",
      "0.06311330101673032 -1\n",
      "-0.2684316700419388 1\n",
      "Accuracy: 0.0\n",
      "-0.0021343552799009957 -1\n",
      "-0.21431846497757076 1\n",
      "-0.013590985595804905 -1\n",
      "-0.19940747075458434 1\n",
      "Accuracy: 0.5\n",
      "0.007708860039234017 -1\n",
      "-0.0602968626075909 1\n",
      "0.05510387390981797 1\n",
      "0.38287794874571196 -1\n",
      "Accuracy: 0.25\n",
      "-0.03249249062128799 1\n",
      "0.174513062246256 -1\n",
      "-0.1619768306133193 1\n",
      "0.07116510392935184 -1\n",
      "Accuracy: 0.0\n",
      "-0.036697974883590626 1\n",
      "0.06771839102477573 -1\n",
      "0.04800575517634843 -1\n",
      "-0.26451862492727307 1\n",
      "Accuracy: 0.0\n",
      "-0.013492246391101512 -1\n",
      "-0.2089164506635982 1\n",
      "0.004838708602860564 -1\n",
      "-0.19617328406759837 1\n",
      "Accuracy: 0.25\n",
      "0.02397216614933434 -1\n",
      "-0.05933584386901217 1\n",
      "0.05553666478756303 1\n",
      "0.3694521228135386 -1\n",
      "Accuracy: 0.25\n",
      "-0.02946109273265729 1\n",
      "0.1645087045160085 -1\n",
      "-0.1568683977666097 1\n",
      "0.0871917337595178 -1\n",
      "Accuracy: 0.0\n",
      "-0.034213891589239556 1\n",
      "0.08189394954248998 -1\n",
      "0.036463982702175005 -1\n",
      "-0.2615637510243784 1\n",
      "Accuracy: 0.0\n",
      "-0.022162461903601827 -1\n",
      "-0.20481850843878235 1\n",
      "0.018912628454699737 -1\n",
      "-0.1936738492845092 1\n",
      "Accuracy: 0.25\n",
      "0.03638875053768069 -1\n",
      "-0.05857795448137543 1\n",
      "0.05584023572632456 1\n",
      "0.35920215406390915 -1\n",
      "Accuracy: 0.25\n",
      "-0.027168242231722234 1\n",
      "0.15687515629108084 -1\n",
      "-0.1529450250055586 1\n",
      "0.09942724304764677 -1\n",
      "Accuracy: 0.0\n",
      "-0.03229874430921155 1\n",
      "0.09271439317380324 -1\n",
      "0.027647199644565607 -1\n",
      "-0.25932885166317504 1\n",
      "Accuracy: 0.0\n",
      "-0.02878118991616907 -1\n",
      "-0.2017068433473062 1\n",
      "0.029659922384631388 -1\n",
      "-0.1917460594478439 1\n",
      "Accuracy: 0.25\n",
      "0.04586853609095265 -1\n",
      "-0.057983701167370325 1\n",
      "0.05605465553611806 1\n",
      "0.35137671089640377 -1\n",
      "Accuracy: 0.25\n",
      "-0.0254316177503863 1\n",
      "0.15105002117755995 -1\n",
      "-0.14993461112726214 1\n",
      "0.10876853672535113 -1\n",
      "Accuracy: 0.0\n",
      "-0.030824542574344804 1\n",
      "0.1009741373102505 -1\n",
      "0.020912578161053214 -1\n",
      "-0.25763616610143114 1\n",
      "Accuracy: 0.0\n",
      "-0.033833962066976614 -1\n",
      "-0.19934214046774962 1\n",
      "0.03786669262673582 -1\n",
      "-0.1902616096150718 1\n",
      "Accuracy: 0.25\n",
      "0.053106184325569405 -1\n",
      "-0.05751990612461437 1\n",
      "0.05620715150453838 1\n",
      "0.3454022397984653 -1\n",
      "Accuracy: 0.25\n",
      "-0.024114726756062355 1\n",
      "0.1466045132101382 -1\n",
      "-0.1476265179762598 1\n",
      "0.11590029052739194 -1\n",
      "Accuracy: 0.0\n",
      "-0.029691243433747017 1\n",
      "0.10727938581802744 -1\n",
      "0.01576874389455621 -1\n",
      "-0.25635262431933 1\n",
      "Accuracy: 0.0\n",
      "-0.03769135440994467 -1\n",
      "-0.19754382857347508 1\n",
      "0.04413335357704405 -1\n",
      "-0.18912010129414653 1\n",
      "Accuracy: 0.25\n",
      "0.05863202834875429 -1\n",
      "-0.05715928387019266 1\n",
      "0.056316337465074015 1\n",
      "0.340840888975007 -1\n",
      "Accuracy: 0.25\n",
      "-0.023115107822942182 1\n",
      "0.1432116438470933 -1\n",
      "-0.1458580566247874 1\n",
      "0.12134518331695364 -1\n",
      "Accuracy: 0.0\n",
      "-0.028820963631525295 1\n",
      "0.11209276134841081 -1\n",
      "0.011840160277691358 -1\n",
      "-0.2553783395242159 1\n",
      "Accuracy: 0.0\n",
      "-0.040636219900772874 -1\n",
      "-0.19617542763921814 1\n",
      "0.04891846789222126 -1\n",
      "-0.18824330518832377 1\n",
      "Accuracy: 0.25\n",
      "0.06285095162183153 -1\n",
      "-0.056879739312842126 1\n",
      "0.056395020387336806 1\n",
      "0.33735839446866317 -1\n",
      "Accuracy: 0.25\n",
      "-0.02235566258386318 1\n",
      "0.1406220086448369 -1\n",
      "-0.14450380785332106 1\n",
      "0.12550223508456732 -1\n",
      "Accuracy: 0.0\n",
      "-0.028153269791113614 1\n",
      "0.11576733855522194 -1\n",
      "0.008839864216293764 -1\n",
      "-0.25463815423885217 1\n",
      "Accuracy: 0.0\n",
      "-0.042884464200823896 -1\n",
      "-0.19513363055091693 1\n",
      "0.05257224317712968 -1\n",
      "-0.1875704755302431 1\n",
      "Accuracy: 0.25\n",
      "0.06607206641244104 -1\n",
      "-0.05666358706543857 1\n",
      "0.05645207085987761 1\n",
      "0.33469956855781047 -1\n",
      "Accuracy: 0.25\n",
      "-0.02177825702366 1\n",
      "0.1386453493951993 -1\n",
      "-0.14346723462657457 1\n",
      "0.12867606876147553 -1\n",
      "Accuracy: 0.0\n",
      "-0.02764139457740722 1\n",
      "0.11857260134306868 -1\n",
      "0.006548603406981435 -1\n",
      "-0.25407540026942044 1\n",
      "Accuracy: 0.0\n",
      "-0.04460089756122887 -1\n",
      "-0.1943401407032905 1\n",
      "0.055362124721457684 -1\n",
      "-0.18705457534025782 1\n",
      "Accuracy: 0.25\n",
      "0.0685313697833377 -1\n",
      "-0.05649679725053999 1\n",
      "0.05649367524596785 1\n",
      "0.33266958986628437 -1\n",
      "Accuracy: 0.25\n",
      "-0.021338977776482596 1\n",
      "0.13713650846169556 -1\n",
      "-0.14267412721297656 1\n",
      "0.13109924567160905 -1\n",
      "Accuracy: 0.0\n",
      "-0.02724922633754215 1\n",
      "0.12071424373820235 -1\n",
      "0.004798877692309439 -1\n",
      "-0.2536472730379164 1\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "y = np.array([-1, 1, 1, -1])\n",
    "widrow_hoff(x, y, 70, 0.1)\n",
    "\n",
    "# Is it true ? ^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsN77tEzyJ0L"
   },
   "source": [
    "#### Exercitiul 4\n",
    "\n",
    "Definim in prima faza functiile de activare ale retelei, tanh si sigmoid si derivata tanh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "oulVSiDVYe45"
   },
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def derivative_tanh(x):\n",
    "    return 1 - tanh(x) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOX0aVd7zBlM"
   },
   "source": [
    "Urmatoarea functie trece un input(X) prin retea si salveaza rezultatele intermediare:\n",
    "- z_1 este rezultatul celui de-al 2-lea strat inainte de functia de activare\n",
    "- a_1 este rezultatul functiei de activare(deci a_1=tanh(z_1)).\n",
    "- z_2 este rezultatul ultimului strat inainte de functia de activare\n",
    "- a_2 este rezultatul dupa aceasta (a_2=sigmoid(z_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "9FTuWgh6TUVC"
   },
   "outputs": [],
   "source": [
    "def forward(X, W_1, b_1, W_2, b_2):\n",
    "\n",
    "  z_1 = X @ W_1 + b_1\n",
    "  a_1 = tanh(z_1)\n",
    "  z_2 = a_1 @ W_2 + b_2\n",
    "  a_2 = sigmoid(z_2)\n",
    "\n",
    "  return z_1, a_1, z_2, a_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision(X_, W_1, W_2, b_1, b_2):\n",
    "\n",
    "  # Sterge continutul ferestrei\n",
    "  plt.clf()\n",
    "\n",
    "  # Setam limitele pentru axelor X si Y\n",
    "  plt.ylim((-0.5, 1.5))\n",
    "  plt.xlim((-0.5, 1.5))\n",
    "\n",
    "  # Generam multe puncte aleatoare in spatiul 2D\n",
    "  xx = np.random.normal(0, 1, (100000))\n",
    "  yy = np.random.normal(0, 1, (100000))\n",
    "\n",
    "  # Combinam datele random cu cele reale (X_)\n",
    "  X = np.array([xx, yy]).transpose()\n",
    "  X = np.concatenate((X, X_))\n",
    "\n",
    "  # Forward pass: rulam toate punctele prin retea sa vedem in ce clasa le clasifica\n",
    "  _, _, _, output = forward(X, W_1, b_1, W_2, b_2)\n",
    "\n",
    "  # Transformam output-ul in etichete binare (0 sau 1)\n",
    "  y = np.squeeze(np.round(output)) # squeeze() elimina dimensiuni redundante (ex: (100000, 1) devine (100000,))\n",
    "\n",
    "  # Punctele din clasa 0 (cu albastru) si din clasa 1 (cu rosu)\n",
    "  plt.plot(X[y == 0, 0], X[y == 0, 1], 'b+')\n",
    "  plt.plot(X[y == 1, 0], X[y == 1, 1], 'r+')\n",
    "\n",
    "  plt.show(block=False)\n",
    "  plt.pause(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gN36f4uZznRG"
   },
   "source": [
    "Functia urmatoare se foloseste de rezultatele intermediare salvate dupa apelul functiei forward pentru a calcula derivata functiei de pierdere in functie de weight-urile retelei (w_1,b_1,w_2,b_2).\n",
    "\n",
    "Formulele aplicate in functia de mai jos sunt obtinute prin chain rule:\n",
    "\n",
    "h(x) = f(g(x))\n",
    "h'(x) = g'(x)*f'(g(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "iYEms389XVSp"
   },
   "outputs": [],
   "source": [
    "def backward(a_1, a_2, z_1, W_2, X, Y, num_samples):\n",
    "  \"\"\"\n",
    "  Params:\n",
    "\n",
    "  X = inputs = datele de intrare\n",
    "  Y = labels/ground-truth\n",
    "  num_samples = batch_size (numărul de exemple)\n",
    "\n",
    "  z_1 = hidden_input      (inputul in stratul ascuns, inainte de tanh: z1 = w1 * X + b1)\n",
    "  a_1 = hidden_activation (iesirea stratului ascuns dupa aplicarea activarii tanh)\n",
    "\n",
    "  W_2 = output_weights    (ponderile intre stratul ascuns si cel de iesire)\n",
    "  a_2 = y_hat             (predictia finala a retelei dupa aplicarea functiei sigmoid)\n",
    "  \"\"\"\n",
    "\n",
    "  dz_2 = a_2 - y # derivata functiei de pierdere (logistic loss) in functie de z\n",
    "  dw_2 = (a_1.T @ dz_2) / num_samples\n",
    "  # der(L/w_2) = der(L/z_2) * der(dz_2/w_2) = dz_2 * der((a_1 * W_2 + b_2)/ W_2)\n",
    "  db_2 = sum(dz_2) / num_samples\n",
    "  # der(L/b_2) = der(L/z_2) * der(z_2/b_2) = dz_2 * der((a_1 * W_2 + b_2)/ b_2)\n",
    "  # primul strat\n",
    "  da_1 = dz_2 @ W_2.T\n",
    "  # der(L/a_1) = der(L/z_2) * der(z_2/a_1) = dz_2 * der((a_1 * W_2 + b_2)/ a_1)\n",
    "  dz_1 = da_1 * derivative_tanh(z_1)\n",
    "  # der(L/z_1) = der(L/a_1) * der(a_1/z1) = da_1 .* der((tanh(z_1))/ z_1)\n",
    "\n",
    "  dw_1 = X.T @ dz_1 / num_samples\n",
    "  # der(L/w_1) = der(L/z_1) * der(z_1/w_1) = dz_1 * der((X * W_1 + b_1)/ W_1)\n",
    "  db_1 = sum(dz_1) / num_samples\n",
    "  # der(L/b_1) = der(L/z_1) * der(z_1/b_1) = dz_1 * der((X * W_1 + b_1)/ b_1)\n",
    "  return dw_1, db_1, dw_2, db_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygQngZf60fNR"
   },
   "source": [
    "Urmeaza initializarea weight-urilor retelei, care se face random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "wUz6ZcLLZLUH"
   },
   "outputs": [],
   "source": [
    "import numpy.random as random\n",
    "\n",
    "num_hidden_neurons = 5\n",
    "miu = 0\n",
    "sigma = 1\n",
    "\n",
    "W_1 = random.normal(miu, sigma, (2, num_hidden_neurons))\n",
    "b_1 = np.zeros(num_hidden_neurons)\n",
    "W_2 = random.normal(miu, sigma, (num_hidden_neurons, 1))\n",
    "b_2 = np.zeros(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTVgk8n30mEl"
   },
   "source": [
    "Algoritmul gradient descent:\n",
    "- Folosim functia forward pentru a calcula valorile intermediare (z_1, a_1, z_2 a_2)\n",
    "- Cu functia backward calculam gradientii\n",
    "- Updatam weight-urile cu gradientii obtinuti si learning_rate-ul stabilit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4hYVCMcdpd-"
   },
   "outputs": [],
   "source": [
    "# Datele de train pentru XOR\n",
    "x = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "y = np.array([[0], [1], [1], [0]]) # Folosim forma de matrice coloana pentru a putea matematic sa ne potrivim cu forma predicției a_2, care are si ea formă de coloana ([batch_size × 1] = [4 x 1])\n",
    "\n",
    "# Hiperparametri\n",
    "epochs = 70\n",
    "learning_rate = 0.5\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "  # Afișăm dreapta de decizie curenta\n",
    "  plot_decision(x, W_1, W_2, b_1, b_2)\n",
    "\n",
    "  z_1, a_1, z_2, a_2 = forward(x, W_1, b_1, W_2, b_2)\n",
    "\n",
    "  loss = (-y * np.log(a_2) - (1 - y) * np.log(1 - a_2)).mean()\n",
    "  accuracy = (np.round(a_2) == y).mean()\n",
    "  print(accuracy)\n",
    "  \n",
    "  dw_1, db_1, dw_2, db_2 = backward(a_1, a_2, z_1, W_2, x, y, len(x))\n",
    "\n",
    "  W_1 -= learning_rate * dw_1\n",
    "  b_1 -= learning_rate * db_1\n",
    "  W_2 -= learning_rate * dw_2\n",
    "  b_2 -= learning_rate * db_2"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ml_practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
