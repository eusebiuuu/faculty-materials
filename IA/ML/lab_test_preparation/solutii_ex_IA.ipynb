{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9acafea-e69f-4495-8fc7-418e4b389240",
   "metadata": {},
   "source": [
    "# Laborator 7 - Model Exercitii Colocviu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b7bf83-68f3-47cc-9780-936f19f056f2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9120c205-d51f-4125-99bf-11e434b2575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from urllib import request\n",
    "import gzip\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110e98bf-e32d-46a5-a2fb-162f5a7e400d",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ba9bc7-9f8d-4eb3-8a20-9eb9d462ca02",
   "metadata": {},
   "source": [
    "- Datele pe care le vom folosi astazi se gasesc intr-un fisier \"data.pkl\", care contine setul de date MNIST sub forma de dictionar Python \"pickle\".\n",
    "\n",
    "De aici luam imaginile si label-urile de antrenare si de testare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fbde7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "    with open(\"data.pkl\",'rb') as f:\n",
    "        mnist = pickle.load(f)\n",
    "    return mnist[\"training_images\"], mnist[\"training_labels\"], mnist[\"test_images\"], mnist[\"test_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10ae1356",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels, test_images, test_labels = load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b4b74d-d0c2-4de8-a10a-edd563d7272f",
   "metadata": {},
   "source": [
    "- Imaginile sunt sub forma de vector pickle, asa ca am vrea sa le formatam inapoi la forma lor originala, o matrice de dimensiunea (N, 28, 28), unde N = numarul de samples.\n",
    "\n",
    "- Daca folosim .reshape() cu primul argument egal cu \"-1\", numpy deduce automat dimensiunea (numarul de imagini).\n",
    "\n",
    "Pasul asta e esential ca sa procesam vecinitatile, din moment ce ele au sens doar in (minim) 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "830b34de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(-1, 28, 28)#[:5000]\n",
    "test_images = test_images.reshape(-1, 28, 28)#[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faa946d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels#[:5000]\n",
    "test_labels = test_labels#[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae6def1-b834-4be1-b40a-37b85ac3809e",
   "metadata": {},
   "source": [
    "- Putem transforma prima imagine intr-un obiect de tip \"Image\" ca sa o vizualizam:\n",
    "\n",
    "'astype(np.uint8)' e necesar pentru ca valorile de intensitate sa fie valide intre 0 si 255.\n",
    "\n",
    "(Pasul acesta nu e esential pentru colocviu, e util doar ca sa intelegem/vizualizam datele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "518816aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APAACzBVBJJwAO9dnp/wm8damu6Dw5dRjGf9IKw/+hkVPffCnWNJa7XVNV0Kxa1hErrNe/M2cnYqgElsAHpjkc1wlAODkV694W8c654t8M6n4TuvEctrrFw0cun3c0/lq+3AMJcDK5AyOeTkd+fPvGFn4gsvEtzF4m89tUG1ZJJjuMgUBVYN/EMKOe9YVXtK0bUtdvVs9LsZ7y4YgbIULYycZPoPc8V6lpfwh0/w7p66z8RdXj0y2z8llC4aWQ+mRn8lz9RXPfE3x1pvi46TYaPZTQadpMJghluWDSyrhQM9SMBe5Oc5NcBV7Tda1XRZJJNK1O8sXkG12tZ2iLD0JUjNQ3l9eahN517dT3MvTfNIXb16n6mq9Ff/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA90lEQVR4AWNgGMyAWUhIqK5jvdSy/9/rQe5kgTlWjs3KRiAYxHsyKfDzxYMgFiOIAALDvfwQBsO/pK8Mz97fhPLAlNDtvyBwbNv3j8jCUHbAnOy/f89yM2jPwiLJwMc4628UqgQTnPvp/0eGFAQXLg5lcO/764YuhuArf3y4IAfmfoQwlBX44e/fckkMYaiA7q6/f6dJ45IViP3zdzcuSQaGn39/OkBl4WEL4euFmLIwXDuETav6lKfAIPy1DYucRNFdUPCe9MOUE3e6CpI6FogZSEKrwbFyOIATQ5v5mkcgXV9auVGlwK4NDGRguL75b88HVDla8QBFF16ADQA8sQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "Image.fromarray(train_images[0].astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5f5337-c8f9-41bf-85fb-ef7e28d9ed12",
   "metadata": {},
   "source": [
    "## Exercitiul 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613bde4f-8600-44b0-a669-43db830e5163",
   "metadata": {},
   "source": [
    "- Avem nevoie de o functie ajutatoare, care sa ne transforme un vector binar (de ex. [1, 0, 1] intr-un numar in baza 10).\n",
    "\n",
    "- In plus, folosim reversed() ca sa punem cel mai putin semnificativ bit la dreapta.\n",
    "\n",
    "- Transformarea (scalarul) o sa fie indexul nostru unic pentru histograma de vectori.\n",
    "\n",
    "Spre exemplu, pentru un patch de 3x3:\n",
    "\n",
    "[[60, 70, 55],\n",
    "\n",
    " [58, 65, 62],\n",
    " \n",
    " [50, 68, 59]]\n",
    "\n",
    " Pixelul central e \"65\", pe care il comparam cu ceilalti 8 si obtinem binary signature-ul: \"01000010\" -> [0, 1, 0, 0, 0, 0, 1, 0]\n",
    "\n",
    " Deci, binary2decimal o sa imi returneze: $results = 0 \\cdot 2^7 + 1 \\cdot 2^6 + ... + 1 \\cdot 2^1 + 0 \\cdot 2^0 = 64 + 2 = 66.$\n",
    "\n",
    " Asadar, pozitia 66 din histograma se incrementeaza cu o frecventa de 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef569be-5bf8-4de0-bd54-96d7d03390b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary2decimal(binary):\n",
    "    return sum(val*(2**idx) for idx, val in enumerate(reversed(binary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "74693828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_ex1(image, d=3):\n",
    "\n",
    "    # Calculam cat ar trebui sa luam din fiecare directie ca sa pastram centrul vecinatatii pixelului/patch-ului in interiorul imaginii.\n",
    "    h, w = image.shape\n",
    "    size_left_right = (d-1)//2 # Pentru d=3, o sa avem 1 pixel la stanga, 1 la dreapta, 1 sus, 1 jos. \n",
    "    size_up_down = (d-1)//2\n",
    "\n",
    "    # Adaugam un padding cu \"-1\" ca sa putem calcula vecinatatile pixelilor din marginile imaginii \n",
    "    # \"-1\" nu influenteaza calculele, deoarece orice pixel real are valoare >=0.\n",
    "    padded_image = np.pad(image, ((size_up_down, size_up_down), (size_left_right, size_left_right)), constant_values=-1) # (28, 28) -> (30, 30)\n",
    "    # Alternativ, pentru cazul de fereastra de 3x3: padded_image = np.pad(image, ((1,1), (1,1)), constant_values=-1)\n",
    "    \n",
    "    # Iteram peste fiecare pixel care are o vecinatate complet definita (evitam intai marginile) \n",
    "    # Vrem sa extragem acel binary signature pt fiecare pixel (cu vecinatatea aferenta)\n",
    "    results = []\n",
    "    for i in range(size_up_down, h):\n",
    "        for j in range(size_left_right, w):\n",
    "\n",
    "            # Initializam un vector de output (d x d) care o sa contina toate valorile binare din comparatia pixelului cu \"vecinii\" sai.\n",
    "            output_representation = np.zeros((d*d)-1)\n",
    "            # Luam un patch de dimensiune tot d x d (3x3 in cazul nostru) centrata pe pixelul curent din iteratie\n",
    "            patch = padded_image[i-size_left_right:i+size_left_right+1,\n",
    "                                 j-size_up_down:j+size_up_down+1]\n",
    "\n",
    "            # Valoare de comparat este chiar valoarea pixelului de la pozitia (i, j)\n",
    "            value = padded_image[i][j]\n",
    "            # Comparam fiecare pixel din patch cu valoarea centrala\n",
    "            # \"*1\" converteste True/False in 1 / 0.\n",
    "            comparison = (patch>value)*1\n",
    "            # Vectorizam patch-ul de comparatii intr-un vector 1D de lungime d*d.\n",
    "            result = comparison.reshape(-1)\n",
    "\n",
    "            # Scoatem valoarea centrala din patch-ul vectorizat (nu vrem sa comparam pixelul cu el insusi)\n",
    "            result = np.delete(result, (d*d)//2)\n",
    "            results.append(result)\n",
    "            \n",
    "            # output_representation[:len(output_representation)//2] = result[:len(output_representation)//2]\n",
    "            # output_representation[len(output_representation)//2:] = result[len(output_representation)//2 + 1:]\n",
    "            # results.append(output_representation)\n",
    "\n",
    "    # Initializam o histograma (vector) de lungime 2^(d*d-1)\n",
    "    # In cazul nostru 2^8 combinatii posibile de biti = 256 de valori/semnaturi diferite pentru pixeli (0-255)\n",
    "    # Histograma e in esenta o reprezentare/semnatura globala a imaginii\n",
    "    # Practic, avem 784 pixeli per imagine -> 784 de vectori/\"semnaturi binare\" -> le agregam count-ul intr-o histograma de frecvente (256 valori posibile)\n",
    "    histogram = np.zeros((2**(d*d-1))) # Histograma = vector/array de frecvente\n",
    "    # 2 ^ 8 = 256\n",
    "    for result in results:\n",
    "        position = binary2decimal(result)\n",
    "        histogram[int(position)]+=1\n",
    "    return histogram\n",
    "\n",
    "def process_data(images):\n",
    "    results = []\n",
    "    # Aplicam f_ex1 pentru fiecare imagine din setul de dat (tqdm ne ajuta pentru progres vizual -> Nu e obligatoriu, dar ajuta la debugging)\n",
    "    for image in tqdm(images):\n",
    "        hist = f_ex1(image)\n",
    "        results.append(hist)\n",
    "    # Obtinem un vector de features pentru tot setul de imagini pe care aplicam functia\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b65549d-4a76-420d-bcbf-a2b603463712",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist = process_data(train_images) # 256 x 5000\n",
    "test_hist = process_data(test_images) # 256 x 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f8ee5558-ea18-4868-ae17-65a8fb93323d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hist[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75f6718-06d3-47bc-863e-93ccbb1eadba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Importam un scaler pentru normalizare si normalizam histogramele (evitam dominanta unor frecvente mari)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_hist)\n",
    "train_hist_scaled = scaler.transform(train_hist)\n",
    "test_hist_scaled = scaler.transform(test_hist)\n",
    "\n",
    "# Antrenam modelul SVM pe histograma normalizata\n",
    "clf = SVC(C = 10, kernel = 'rbf', gamma = 0.001)\n",
    "clf.fit(train_hist_scaled, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "aea0ac90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.75 %\n"
     ]
    }
   ],
   "source": [
    "# Calculam acuratetea pe setul de test\n",
    "print(\"Accuracy:\", clf.score(test_hist_scaled, test_labels) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feecd2b-a29d-4fef-b0f4-29ec6d91a570",
   "metadata": {},
   "source": [
    "### De ce am obtinut atat?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781a49e7-f6e2-4695-b8e1-4bb83545cd0f",
   "metadata": {},
   "source": [
    "O acuratete de 77.75% e acceptabila pentru o metoda facuta \"de mana\".\n",
    "\n",
    "Avantaje:\n",
    "- Nu am folosit pixelii bruti, ci niste reprezentari bazate pe semnaturi binare (similar cu LBP - Local Binary Patterns)\n",
    "- Vectorul de features cu care lucram are 256 dimensiuni per imagine, deci datele sunt comprimate, iar SVM lucreaza bine eficient\n",
    "- Nu ne folosim de DL sau retele convolutionale, e doar ML clasic cu prelucrare de date\n",
    "\n",
    "Dezavantaje:\n",
    "- Binary signature-ul calculat de noi pierde informatii, deoarece:\n",
    "  - Nu tine cont de valoarea absoluta, doar de \"mai mare\" sau \"mai mic\" decat pixelul centrat\n",
    "  - Nu invata formele sau muchiile complexe, pentru ca histograma sterge informatia de pozitie. Fiecare vector binar e agregat global, ceea ce inseamna ca de exemplu Imaginile cu \"2\" si cele cu \"5\" pot avea parti comune ca binary signatures, adica o histograma similara."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e2abc2-88ad-42c8-8133-97f06b4af04f",
   "metadata": {},
   "source": [
    "## Exercitiul 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df2aa89-7b71-4bdd-ab6c-5f22e35f3403",
   "metadata": {},
   "source": [
    "In esenta, vrem sa calculam magnitudinea gradientului unei imagini, sa o impartim in regiuni de 3x3, dupa care sa selectam cele mai \"informative\" k regiuni (care au gradient mediu mare), si sa le folosim pentru antrenarea unui model ML.\n",
    "\n",
    "- Gradientul ne ofera o masura locala a variatiei intensitatii; E util pentru a identificare contururi, margini, regiuni mai informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a833ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Calculam magnitudinea gradientului unei imagini folosind filtrul Sobel\n",
    "# Sobel = filtru (kernel) folosit in CV pentru a estima gradientul intensitatii intr-o imagine. \n",
    "# Practic, detecteaza margini, contururi si zone unde apar modificari bruste in imagine (luminozitatea locala)\n",
    "# E o aproximare discreta a primelor derivate si foloseste doua matrici de convolutie (pentru Ox si Oy).\n",
    "def compute_gradient_magnitude(image):\n",
    "    # Aplica filtrul Sobel pe directia Ox (orizontala)\n",
    "    gx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3) # CV_64F = precizie ridicata, evita pierderea semnelor negative \n",
    "                                                         # ksize = 3 -> kernel Sobel de (3x3)\n",
    "    # Aplica filtrul Sobel pe directia Oy (verticala)\n",
    "    gy = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3) \n",
    "\n",
    "    # Formula exacta pentru magnitudinea gradientului\n",
    "    grad_mag = np.sqrt(np.square(gx) + np.square(gy))  # Cat de \"puternic\" e conturul\n",
    "    return grad_mag # grad_mag.shape == (28, 28) | Fiecare pixel contine cat de \"abrupt\" se schimba intensitatea in zona aceea.\n",
    "\n",
    "# Pentru fiecare imagine, calculam gradientul (tqdm doar adaug un progress bar)\n",
    "def process_images(images):\n",
    "    results = []\n",
    "    for image in tqdm(images):\n",
    "        results.append(compute_gradient_magnitude(image))\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b3f4b4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 37664.16it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 39318.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# Calculam matricea de gradienti pentru seturile de antrenare si testare\n",
    "train_grad_mag = process_images(train_images)\n",
    "test_grad_mag = process_images(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9aabb95a-4c7e-4389-a5d6-8274e0415a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images shape: (5000, 28, 28)\n",
      "train_grad_mag shape: (5000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# In rezultatul final, train_grad_mag[i] are aceleasi dimensiuni ca train_images[i], dar valorile sunt magnitudini de gradient.\n",
    "print(\"train_images shape:\", train_images.shape)\n",
    "print(\"train_grad_mag shape:\", train_grad_mag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3f4150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selectam cele mai informative \"k\" regiuni de dimensiuni (d, d) din imaginea \"original_image\", careia ii corespunde gradientul \"grad_mag\"\n",
    "def get_top_k_regions(grad_mag, original_image, k=30, d=4): #30/49\n",
    "    # Presupunem ca imaginea are dimensiuni divizibile exact cu \"d\"\n",
    "    # In cazul nostru, 28x28 = 784 pixeli -> pentru d=4, o sa avem 7x7 patch-uri de 4x4\n",
    "\n",
    "    # Transformam imaginea intr-un vector de patch-uri de dimensiuni (d, d). Numpy stie singur ca o sa obtina 49 de patch-uri, de aceea punem \"-1\".\n",
    "    patches_mag = grad_mag.reshape(-1, d, d) # patches_mag.shape == (49, 4, 4)\n",
    "    original_image = original_image.reshape(-1, d, d)\n",
    "\n",
    "    # Calculam media gradientului in fiecare patch => masura noastra pentru complexitate / \"informatie\" / scor de importanta vizuala per patch\n",
    "    patches_mag = np.mean(patches_mag, axis=(1, 2))  # patches_mag.shape == (49,)\n",
    "\n",
    "    # Sortam patch-urile in functie de relevanta (gradientii slabi -> sus, iar cei puternici -> jos)\n",
    "    sorted_indices = np.argsort(patches_mag)\n",
    "\n",
    "    # Pastram doar patch-uri originale corespunzatoare celor mai \"puternice\" k regiuni din gradient\n",
    "    output = original_image[sorted_indices[-k:]]\n",
    " \n",
    "    # Concatenam toate patch-uri selectate intr-un singur vector\n",
    "    return np.array(output).reshape(-1)\n",
    "\n",
    "# Pentru fiecare imagine, extragem patch-urile informative si le transformam intr-un vector\n",
    "# NU PASTRAM VALORILE DE GRADIENT ALE PATCH-URILOR! Ci patch-urile brute din imaginea originala, dar doar cele cu media gradientului cea mai mare.\n",
    "def transform_images(images, grad_mags):\n",
    "    results = []\n",
    "    for i, image in enumerate(tqdm(images)):\n",
    "        output = get_top_k_regions(grad_mags[i], image)\n",
    "        results.append(output)\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059192ba-5139-4a0f-86e7-a6c5afb505e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 40383.28it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 38947.04it/s]\n"
     ]
    }
   ],
   "source": [
    "ex2_train_data = transform_images(train_images, train_grad_mag)\n",
    "ex2_test_data = transform_images(test_images, test_grad_mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a995261-7c31-4121-9525-4cda8f365ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ex2_train_data shape: (5000, 480)\n",
      "ex2_test_data shape: (2000, 480)\n"
     ]
    }
   ],
   "source": [
    "# Rezultatul final ex2_train_data are dimensiunea (N, k*d*d) = (5000, 30* 4*4) => Fiecare imagine devine un vector de features de dimensiune fixa\n",
    "# 5000 de imagini, 30 de patch-uri pastrate, 16 valori per patch. Practic extragem cei mai relevanti 480 pixeli din 784.\n",
    "print(\"ex2_train_data shape:\", ex2_train_data.shape)\n",
    "print(\"ex2_test_data shape:\", ex2_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0df963c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(C=10)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(ex2_train_data)\n",
    "ex2_train_data_scaled = scaler.transform(ex2_train_data)\n",
    "ex2_test_data_scaled = scaler.transform(ex2_test_data)\n",
    "\n",
    "clf = SVC(C=10)\n",
    "clf.fit(ex2_train_data_scaled, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86de0217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 47.05 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", clf.score(ex2_test_data_scaled, test_labels) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f64e71-3dff-4908-be52-dd01bcf66caa",
   "metadata": {},
   "source": [
    "### De ce am obtinut mai bine decat la Ex. 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70b8f30-93fb-463c-9a6e-70fdc3f361da",
   "metadata": {},
   "source": [
    "Fata de exercitiul anterior, care era bazat pe comparatii locale si pierdea informatiile de pozitie, acum am pastrat mai multa informatie vizuala utila:\n",
    "\n",
    "- Am ales doar zonele cu variatie locala mare (margini, forme), care sunt mai reprezentative pentru cifre\n",
    "- Am pastrat valorile reale brute ale pixelilor, nu doar relatii binare\n",
    "- Chiar daca nu avem o structura spatiala, cele mai informative patch-uri tin sa apara in zone cheie ale cifrelor (mijloc, bucle etc.), deci patch-urile pastreaza o \"urma\" de pozitie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aaa797-e498-4424-9c97-5948356afa5d",
   "metadata": {},
   "source": [
    "## Exercitiul 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e543e3-38ae-48b4-bf7a-6ca532fde1a1",
   "metadata": {},
   "source": [
    "Similar cu exercitiul anterior, vrem sa calculam magnitudinea si directia gradientului.\n",
    "\n",
    "Dupa care, pentru fiecare pixel, comparam magnitudinea gradientului sau cu a celor doi vecini de pe directia gradientului (Ox sau Oy). Daca e mai mare decat amandoi, pastram valoarea, altfel punem 0.\n",
    "\n",
    "Mai exact:\n",
    "- Calculam gradientul de intensitate pe directiile x si y (sobelx, sobely)\n",
    "- Obtinem magnitudinea gradientului (cat de puternica e variatia) si directia acestuia\n",
    "- Facem NMS - comparam fiecare pixel cu vecinii de pe directia gradientului (pastram doar maximele locale)\n",
    "- Obtinem o imagine trecuta prin NMS (non-maximum suppression), noua, tot de dimensiune 28x28, in care:\n",
    "  - Doar marginile semnificative au valori nenule\n",
    "  - Restul pixelilor sunt 0\n",
    "\n",
    "Gradientul intr-o imagine e un vector care ne spune\n",
    "\n",
    "\"Cat de repede si in ce directie se schimba intensitatea pixelilor in vecinatatea unui punct?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d879c13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 5000/5000 [00:00<00:00, 27205.50it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 2000/2000 [00:00<00:00, 36948.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# Calculam magnitudinea fiecarui gradient identic cu exercitiul anterior, folosint filtrul Sobel\n",
    "# Parametrii in plus \"1\" si \"0\" reprezinta derivata pe x si y (pe directie: dx, dy)\n",
    "# In esenta Gx si Gy sunt componentele gradientului intr-o imagine (pentru ca gradientul variaza in 2 directii => imaginea e o matrice 2D)\n",
    "def compute_gradient_direction(image):\n",
    "    sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3) # Gx\n",
    "    sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3) # Gy\n",
    "    # Calculam unghiul directiei gradientului in radiani\n",
    "    grad_direction = np.arctan2(sobely, sobelx) # In ce directie \"urca\" intensitatea\n",
    "    # Folosim artcan2 si nu arctan ca sa tinem cont de semnele lui Gx si Gy\n",
    "    # => unghiul corect in toate cadranele (ex. pentru Gx = -1 si Gy = 1, ar trebui sa avem valoarea de -135 de grade. Dar Gy/Gx = -1 => arctan(-1) = 45*\n",
    "    # Arctan2 elimina ambiguitatea si e standard in CV ca sa obtinem directii corecte ale gradientului\n",
    "    return grad_direction\n",
    "\n",
    "# Aplicam functia pe toate imaginile\n",
    "def process_directions(images):\n",
    "    results = []\n",
    "    for image in tqdm(images):\n",
    "        results.append(compute_gradient_direction(image))\n",
    "    return np.array(results)\n",
    "\n",
    "train_grad_direction = process_directions(train_images)\n",
    "test_grad_direction = process_directions(test_images)\n",
    "\n",
    "def non_max_suppression_gradient(img, direction):\n",
    "    h, w = img.shape\n",
    "    # Convertim unghiurile din radiani in grade, si ne asiguram ca toate sunt in intervalul [0, 180]\n",
    "    output = np.zeros((h,w), dtype=np.int32)\n",
    "    # angle = arctan2(Gy, Gx) e in intervalul [-pi, pi]\n",
    "    angle = direction * 180. / np.pi # Transformam radianii in grade\n",
    "    angle[angle < 0] += 180 # Transformam unghiurile in echivalentele lor pozitive (e.g. -45 devine 135, ca sa avem tot intre 0 si 180 grade)\n",
    "\n",
    "    # Luam vecinii de pe directia gradientului\n",
    "    # Iteram doar pe interiorul imaginii (evitam marginile)\n",
    "    for i in range(1, h-1):\n",
    "        for j in range(1, w-1):\n",
    "            # Initializam vecinii la 255 ca fallback (valoare mare, deci pixelul probabil nu va fi pastrat)\n",
    "            neighbour1 = 255\n",
    "            neighbour2 = 255\n",
    "\n",
    "            # Impartim in 4 intervale de directie (aproximativ) deoarece NMS presupune ca sa comparam un pixel cu 2 vecini pe directia gradientului\n",
    "            # Intr-o imagine 2D, deci, o sa avem 8 vecini posibili in jurul unui pixel\n",
    "            # [0, 22.5)        → directie 0°  \n",
    "            # [22.5, 67.5)     → directie 45°  \n",
    "            # [67.5, 112.5)    → directie 90°  \n",
    "            # [112.5, 157.5)   → directie 135°  \n",
    "            # [157.5, 180]     → directie 0°\n",
    "\n",
    "            # Directia 0 - orizontala\n",
    "            if (0 <= angle[i,j] < 22.5) or (157.5 <= angle[i,j] <= 180):\n",
    "                neighbour1 = img[i, j+1] # Dreapta pixelului\n",
    "                neighbour2 = img[i, j-1] # Stanga pixelului\n",
    "\n",
    "            # Directia 1 - diagonala \n",
    "            elif (22.5 <= angle[i,j] < 67.5):\n",
    "                neighbour1 = img[i+1, j-1] # Stanga jos de pixel\n",
    "                neighbour2 = img[i-1, j+1] # Dreapta sus de pixel\n",
    "\n",
    "            # Directia 2 - verticala\n",
    "            elif (67.5 <= angle[i,j] < 112.5):\n",
    "                neighbour1 = img[i+1, j] # Jos (sub pixel)\n",
    "                neighbour2 = img[i-1, j] # Sus (peste pixel) \n",
    "\n",
    "            # Directia 2 - cealalta diagonala\n",
    "            elif (112.5 <= angle[i,j] < 157.5):\n",
    "                neighbour1 = img[i-1, j-1] # Stanga sus de pixel\n",
    "                neighbour2 = img[i+1, j+1] # Dreapta jos de pixel\n",
    "\n",
    "            # Daca pixelul e mai mare sau egal decat vecinii de pe directia gradientului, pastram valoarea. Altfel, il \"suprimam\" la 0.\n",
    "            if (img[i,j] >= neighbour1) and (img[i,j] >= neighbour2):\n",
    "                output[i,j] = img[i,j]\n",
    "            else:\n",
    "                output[i,j] = 0\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Procesam toate imaginile cu functia anterioara\n",
    "def process_image_with_nms(mags, directions):\n",
    "    results = []\n",
    "    for i, mag in enumerate(mags):\n",
    "        results.append(non_max_suppression_gradient(mag, directions[i]))\n",
    "        \n",
    "    return np.array(results)\n",
    "\n",
    "new_train_mags = process_image_with_nms(train_grad_mag, train_grad_direction)\n",
    "new_test_mags = process_image_with_nms(test_grad_mag, test_grad_direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0d0e9c-aff8-44b7-9372-66df002f52ba",
   "metadata": {},
   "source": [
    "SVM se antreneaza pe imaginile procesare dupa NMS:\n",
    " - new_train_mags are forma (5000, 28, 28) si trebuie aplatizat la (5000, 784)\n",
    "\n",
    "Multe din feature-urile finale sunt zero (datorita NMS)\n",
    "\n",
    "De data aceasta vom folosi alta metoda de scalare, si anume MinMaxScaler, deoarece:\n",
    "- Datele noastre dupa ce aplicam NMS sunt sparse (majoritatea valorilor sunt 0)\n",
    "- Doar marginile/contururile au valori semnificative\n",
    "\n",
    "StandardScaler incearca sa centreze datele la media 0 si deviata standard 1, dar e bun cand avem trasaturi distribuite normal, fara valori sparse. In cazul nostru, media e aproape de 0, deci valorile informative devin prea mici => se pierde contrastul dintre \"edge\" si \"non-edge\".\n",
    "\n",
    "MinMaxScaler aduce toate valorile in intervalul [0, 1] si e bun cand avem date sparse, intensitati etc. El pastreaza proportiile relative si nu strica contrastul dintre noise (in cazul nostru \"0\") si valoril mai mari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f11e917a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-8 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-8 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-8 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-8 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-8 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-8 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(C=10)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Reshape imaginile in formatul (N, 784)\n",
    "X_train = new_train_mags.reshape(-1, 784)\n",
    "X_test = new_test_mags.reshape(-1, 784)\n",
    "\n",
    "# Aplicam scalarea\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "clf = SVC(C=10, kernel = 'rbf')\n",
    "clf.fit(X_train_scaled, train_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "06aa1f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 84.95 %\n"
     ]
    }
   ],
   "source": [
    "# Evaluare\n",
    "score = clf.score(X_test_scaled, test_labels)\n",
    "print(\"Test Accuracy:\", score * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b930e15-c085-4a03-82d3-13a1b0bcb83a",
   "metadata": {},
   "source": [
    "## Exercitiul 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c932f7a-362f-40cb-8a43-332eefb96b25",
   "metadata": {},
   "source": [
    "Exercitiul 4 presupune urmatoarele lucruri:\n",
    "- Impartirea fiecarei imagini in patch-uri (similar cu 1 si 2)\n",
    "- Pentru fiecare patch, sa obtinem un binary signature (ca la ex1, unde facusem comparatiile fata de pixelul central)\n",
    "- Concatenarea acestor vectori binari -> Avem un vector final per fiecare imagine\n",
    "- Antrenarea KNN folosind distanta Hamming (numarul de pozitii din doua stringuri care difera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "526ecc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_image(image, d=4):\n",
    "    '''\n",
    "    Functia binarize_image transforma o imagine intr-un vector binar:\n",
    "    1. Imparte imaginea in patch-uri d x d (trebuia ca dimensiunea imaginii sa fie divizibila \n",
    "    2. Pentru fiecare patch, compara pixelii cu pixelul central (impar) sau media centrala (par)\n",
    "    3. Rezultatul este un vector de 0/1 per patch, toate concatenate\n",
    "    '''\n",
    "    patches = image.reshape(-1, d, d) # Pentru d=4, avem 49 de patch-uri.\n",
    "    outputs = []\n",
    "    \n",
    "    # Iteram prin fiecare patch ca sa il transformam in vector binar\n",
    "    for patch in patches:\n",
    "        # Pentru patch-uri de dimensiune para (e.g. 4x4, 6x6 etc.)\n",
    "        if d % 2==0:\n",
    "            # NU scoatem pixelul central (nu exista de comparat), deci vectorul binar pastreaza d^2 pixeli.\n",
    "            output_representation = np.zeros((d*d))\n",
    "            # NU exista un singur \"pixel central\" -> luam media din blocul de 2x2 din mijloc\n",
    "            value = np.mean(patch[d//2 - 1: d//2 + 1, \n",
    "                                  d//2 - 1: d//2 + 1])\n",
    "\n",
    "        # Trebuie sa tratam ambele cazuri, si de patch-uri pare si impare, deoarece aici nu se suprapun si nu mai facem sliding window\n",
    "        # Pentru patch-uri de dimensiune impara (e.g. 3x3, 5x5, etc.)\n",
    "        else:\n",
    "            # Eliminam pixelul central (nu ne comparam cu noi insine), deci vectorul binar are dimensiunea d^2 - 1.\n",
    "            output_representation = np.zeros((d*d)-1)\n",
    "            # Pixelul central e cel de la pozitia d//2, d//2 (in cazul unui 3x3 ar fi (1,1) )\n",
    "            value = patch[d//2, d//2]\n",
    "\n",
    "        # Comparam fiecare pixel cu valoarea de referinta si producem un array (True/False -> 0/1 cu ajutorul *1)\n",
    "        comparison = (patch>=value)*1\n",
    "        # Aplatizam patch-ul\n",
    "        result = comparison.reshape(-1)\n",
    "\n",
    "        # In cazul patch-urilor de dimensiune para, nu trebuie sa stergem niciun pixel din output-ul final\n",
    "        if d % 2==0:\n",
    "            output_representation = result\n",
    "        # In cazul impar, similar cu ex 1, eliminam valoarea centrala din vectorul aplatizat\n",
    "        else:\n",
    "            output_representation = np.delete(result, d*d // 2)\n",
    "\n",
    "        outputs.append(output_representation)\n",
    "\n",
    "    # Obtinem un singur vector binar mare (toate patch-urile concatenate)\n",
    "    # e.g. pentru o imagine cu 49 de patch-uri de 4x4, rezultatul final o sa aiba 49*16 = 784 biti\n",
    "    return np.concatenate(outputs)\n",
    "\n",
    "def process_data(images):\n",
    "    results = []\n",
    "    for image in tqdm(images):\n",
    "        results.append(binarize_image(image))\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8db6b2-2976-4b05-8edb-7043bc1d435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_binary_data = process_data(train_images)\n",
    "test_binary_data = process_data(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eacd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Test Accuracy: 86.25 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Aici nu avem nevoie de scaler, deoarece deja avem vectori binari pe care aplicam distanta Hamming\n",
    "neigh = KNeighborsClassifier(n_neighbors = 7, metric = 'hamming')\n",
    "\n",
    "neigh.fit(train_binary_data, train_labels)\n",
    "print(\"KNN Test Accuracy:\", neigh.score(test_binary_data, test_labels)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433e2056-d46c-45f1-a2ef-f4c364c503be",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### De ce am obtinut un rezultat bun?\n",
    "\n",
    "- Patch-urile pastreaza o oarecare localizare si structura (pentru ca fiecare patch e un mic signature vizual, concatenarea lor mentine ordinea)\n",
    "- Binarizarea reduce noise-ul (elimina diferentele mici de intensitate intre pixeli)\n",
    "- Hamming Distance e foarte eficienta pentru a diferentia cati biti difera intre doua imagini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24b869e-4ac9-49c1-bd04-fed036eab796",
   "metadata": {},
   "source": [
    "## Exercitiul 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94ee7cd-9c57-4ab1-a869-5b641a77c8d1",
   "metadata": {},
   "source": [
    "Vrem sa folosim histogramele calculate la exercitiul 1 ca sa antrenam un SVM cu kernel de intersectie (Intersection Kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eefc706-2c6a-4fb3-afaf-ccda84e919de",
   "metadata": {},
   "source": [
    "### Ce e un Intersection Kernel?\n",
    "\n",
    "E o functie de similaritate intre doua histograme discrete (vectori pozitivi) si e definita ca\n",
    "\n",
    "$$ K(h_1, h_2) = \\sum_{i=1}^n min(h_1[i], h_2[i]) $$\n",
    "\n",
    "- Masoara cat de mult se suprapun doua histograme\n",
    "- Daca doua distributii au valori similare in aceleasi pozitii, scorul va fi mai mare\n",
    "- E folosit in clasificare de imagini, recunoastere de forme etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "78abc26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definim functia kernelului de intersectie\n",
    "def intersection_kernel(hist1, hist2):\n",
    "    return np.sum(np.minimum(hist1, hist2))\n",
    "\n",
    "# Creem o matrice de similaritate intre doua seturi de histograme\n",
    "def compute_kernel_matrix(histograms1, histograms2, train=True):\n",
    "    # histograms1.shape == (5000, 256) | histograms2.shape == (2000, 256)\n",
    "    kernel_matrix = np.zeros((len(histograms1), len(histograms2)))\n",
    "\n",
    "    # In cazul de antrenare, construim matricea simetric (optimizare)\n",
    "    # Comparam fiecare xi cu fiecare xj din setul de antrenare -> Rezultatul are dimensiunea (n_train, n_train) = (5000, 5000) -> matrice simetrica\n",
    "    if train:\n",
    "        for i in tqdm(range(len(histograms1))):\n",
    "            for j in range(i, len(histograms2)):\n",
    "                similarity = intersection_kernel(histograms1[i], histograms2[j])\n",
    "                kernel_matrix[i][j] = similarity\n",
    "                kernel_matrix[j][i] = similarity\n",
    "    # In cazul de testare, comparam fiecare histograma din setul de test x_i cu fiecare histograma din setul de antrenare x_j\n",
    "    # Comparam fiecare xi din test cu fiecare xj din train -> Rezultatul are dimensiunea (n_test, n_train) = (2000, 5000) -> asimetrica, nu putem optimiza\n",
    "    # Scorurile de similaritate obtinute sunt folosite pentru a determina cat de apropiata de imaginea de test fata de clasele invatate\n",
    "    else:\n",
    "        for i in tqdm(range(len(histograms1))):\n",
    "            for j in range(len(histograms2)):\n",
    "                kernel_matrix[i][j] = intersection_kernel(histograms1[i], histograms2[j])\n",
    "    return kernel_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d972c2-cab9-4a39-b648-e2807d190863",
   "metadata": {},
   "source": [
    "Concret, train_matrix[i][j] contine similaritatea (intersectia) dintre histograma imaginii i si histograma imaginii j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "3f2c3a7a-9305-4841-a3d0-946f38f386ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:59<00:00, 83.78it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:45<00:00, 44.21it/s]\n"
     ]
    }
   ],
   "source": [
    "train_matrix = compute_kernel_matrix(train_hist_scaled, train_hist_scaled)\n",
    "test_matrix = compute_kernel_matrix(test_hist_scaled, train_hist_scaled, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "5dcb5fd5-9a69-48a9-91f2-0e6411bf73c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Matrix shape: (5000, 5000)\n",
      "Test Matrix shape: (2000, 5000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Matrix shape:\", train_matrix.shape)\n",
    "print(\"Test Matrix shape:\", test_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03889c16-e8cd-4682-bc6c-57e7071e7ea5",
   "metadata": {},
   "source": [
    "Cand spunem kernel precomputed, suntem responsabili sa construim o matrice de similaritate intre toate exemplele, in loc sa dam direct X_train cu features. \n",
    "\n",
    "Adica o matrice care contine:\n",
    "\n",
    "$$ K_{i, j} = K(x_i, x_j) $$, unde $x_i$ si $x_j$ sunt exemple de input.\n",
    "\n",
    "kernel = 'precomputed' ii spune lui SVM ca deja ii dam matricea de kernel, fara sa mai foloseasca 'linear', 'rbf' etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c57fd-734d-45f1-90d5-d7b345ad7294",
   "metadata": {},
   "source": [
    "SVC asteapta la antrenare un $(train\\_matrix, y_{train})$:\n",
    "\n",
    "- train_matrix trebuie sa aiba shape-ul $= (n_{train}, n_{train})$\n",
    "    - Fiecare rand \"i\" e imaginea \"i: din train, iar fiecare coloana \"j\" e imaginea \"j\" din train\n",
    " \n",
    "$$ train\\_matrix[i][j] = kernel(x_i, x_j) $$\n",
    "\n",
    "La testare:\n",
    "\n",
    "- test_matric trebuie sa aiba sahape-ul $(n_{test}, n_{train})$\n",
    "    - Fiecare rand e o imagine de test, iar fiecare coloana e o imagine de train\n",
    "\n",
    "$$ test\\_matrix[i][j] = kernel(x_{\\text{test}_i},\\ x_{\\text{train}_j}) $$\n",
    "\n",
    "Comparam fiecare de imagine de test cu TOATE imaginile din train, ca sa o clasificam.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762c5477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Intersection SVM Accuracy: 81.15 %\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C = 0.01, kernel='precomputed') # \n",
    "\n",
    "clf.fit(train_matrix, train_labels)\n",
    "\n",
    "# Facem transpusa matricii kernel de test pentru ca SVM se asteapta la shape = (n_test, n_train) si noi avem invers\n",
    "print(\"Kernel Intersection SVM Accuracy:\", clf.score(test_matrix, test_labels)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783a6c59-36b3-42d8-9246-adc79ffd45e9",
   "metadata": {},
   "source": [
    "## Final observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7bff5a-23e1-4c41-8ae5-29863dc6f48d",
   "metadata": {},
   "source": [
    "#### Exercitiul 1 - Local Binary Pattern\n",
    "\n",
    "E o metoda de descriere a texturii unei imagini. Pentru fiecare pixel, comparam vecinii din jur (de obicei 3x3) cu valoarea pixelului central. Daca vecinul >= pixelul central, asignam valoarea 1, altfel 0. Rezulta un vector binar care encodeaza textura locala. Dupa care, acest vector e transformat in valoare zecimala si se face histograma pe imagine.\n",
    "\n",
    "La Exercitiul 1 am implementat o varianta personalizata de LBP: am implementat o fereastra custom dxd, am creat semnatura binara, dupa care am creat histograma globala.\n",
    "\n",
    "- Buna pentru descrierea texturii locala\n",
    "- Rapida si eficienta pt imagini simple (caractere, semne etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7254a7da-4432-475b-b2be-f02e050e10fd",
   "metadata": {},
   "source": [
    "#### Exercitiul 2 - Magnitudinea Gradientului\n",
    "\n",
    "Gradientul unei imagini (2D) descrie cat de rapid se schimba intensitatea pixelilor. E practic un vector (Gx, Gy), unde Gx e variatia pe orizontala, iar Gy e variatia pe verticala.\n",
    "\n",
    "La Exercitiul 2 am aplicat operatorul Sobel pentru a calcula componentele gradientului Gx si Gy, am extras doar zonele cele mai relevante (cu magnitudine mare), adica unde avem contururi si margini clare, si am pastrat cele mai semnificate 30 de regiuni (cele mai mari medii de gradient).\n",
    "\n",
    "- Bun pentru evidentiere de margini, forme, contururi\n",
    "- Eficient in recunoastere de obiecte\n",
    "- Se concentreaza doar pe forme, nu pe culoare sau textura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdecdd0c-8120-41a1-a301-cfb25ec9821b",
   "metadata": {},
   "source": [
    "#### Exercitiul 3 - Directia Gradientului + NMS\n",
    "\n",
    "Directia gradientului e orientarea schimbarii de intensitate (pe oblica, pe verticala etc.)\n",
    "\n",
    "NMS (Non-Maximum Suppression) retine doar pixelii de pe directia gradientului care sunt maximi local. Elimina valori redundante sau neclare. E folosit in special in Edge Detection (algoritmul Canny), Feature Selection, Object Detection etc. Scopul e sa rarefieze contururile, pastrand doar pixelii maximali in \"fereastra\" lor de 3 pixeli, nu sa distruga complet.\n",
    "\n",
    "La Exercitiul 3, am calculat directia gradientului pentru fiecare pixel, am aplicat NMS ca sa pastram pixelii maximali, dupa care am aplatizat imaginea rezultata si am folosit-o ca feature vector pentru SVM.\n",
    "\n",
    "- Filtrare fina a marginilor\n",
    "- Ne da o reprezentare mai curata a imaginii/structural vorbind\n",
    "- Mentine doar cele mai relevante contururi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38123b3c-6450-4c5c-80df-32c725e5769c",
   "metadata": {},
   "source": [
    "#### Exercitiul 4 - Binary Signature pe regiuni + Hamming KNN\n",
    "\n",
    "La Exercitiul 4, am impartit imaginea in patch-uri care nu se suprapun, si pentru fiecare patch am generat un vector binar pe baza mediei sau valorii centrale. Dupa care, am concatenat acesti vectori intr-un vector binar mare (lungime 784 pentru 49 patch-uri de 4x4) si am folosit KNN cu distanta Hamming, care a masurat cati biti difera intre doua imagini.\n",
    "\n",
    "- Vectorii binari sunt eficienti ca memorie si rapizi la comparare\n",
    "- Distanta Hamming e naturala pentru reprezentari de genul asta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b978fd-e1b3-4689-a139-bb79a6eb287f",
   "metadata": {},
   "source": [
    "#### Exercitiul 5 - Kernel de Intersectie intre Histograme\n",
    "\n",
    "La Exercitiul 5, am comparat histograme generate de Exercitiul 1 intre ele. Am folosit kernelul de intersectie, care e o functie de similaritate ce masoara cat de mult se \"suprapun\" doua histograme. El e pozitiv definit, deci e valid ca si kernel pentru SVM.\n",
    "\n",
    "In formula pentru kernel, daca xi = yi pentru toate i, atunci suma e maxima => similaritate mare.\n",
    "Daca xi = 0 sau yi = 0 in multe locuri, suma scade => similaritate mica.\n",
    "\n",
    "Deci, chiar daca kernelul de intersectie e doar o suma, el reflecta volumul comun dintre doua histograme (efectiv intersectia dintre ele)\n",
    "\n",
    "- Bun pentru clasificare de imagini reprezentate prin histograme (LBF, SIFT, HOG etc.)\n",
    "- Util cand valorile sunt frecvente sau conteaza distributia (nu pozitia exacta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
